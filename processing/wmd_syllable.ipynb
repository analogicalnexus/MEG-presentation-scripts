{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working Memory Decoding\n",
    "============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from mne import create_info, EpochsArray\n",
    "from mne.baseline import rescale\n",
    "from mne.time_frequency import (tfr_multitaper, tfr_stockwell, tfr_morlet,\n",
    "                                tfr_array_morlet)\n",
    "\n",
    "import warnings\n",
    "from mne.preprocessing import ICA\n",
    "warnings.filterwarnings('ignore')\n",
    "from mne import viz\n",
    "from mne.channels import Layout\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator,\n",
    "                          cross_val_multiscore, LinearModel, get_coef)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mne import Epochs, find_events, create_info\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "from mne.time_frequency import AverageTFR\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - IO\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading fif file\n",
    "input_fname = '/media/analogicalnexus/2568212B752CDB3B/MEG_Data/R2504_WMD-Filtered-raw.fif'\n",
    "input_ica = '/media/analogicalnexus/2568212B752CDB3B/MEG_Data/R2504_ica_filtered.fif'\n",
    "raw=mne.io.read_raw_fif(input_fname)\n",
    "raw.load_data()\n",
    "# raw.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Filtering - Band Pass filter (1-45 Hz)\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Band pass filter\n",
    "raw_filtered = raw.filter(l_freq=1, h_freq=45.0, fir_design='firwin')\n",
    "# raw_40.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise Cancellation - Already done in the data collection step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - ICA\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference - https://martinos.org/mne/dev/auto_tutorials/plot_ica_from_raw.html\n",
    "#ICA parameters\n",
    "n_components = 0.95  # if float, select n_components by explained variance of PCA\n",
    "method = 'fastica'  # for comparison with EEGLAB try \"extended-infomax\" here\n",
    "decim = 3  # we need sufficient statistics, not all time points -> saves time\n",
    "\n",
    "# we will also set state of the random number generator - ICA is a\n",
    "# non-deterministic algorithm, but we want to have the same decomposition\n",
    "# and the same order of components each time this tutorial is run\n",
    "random_state = 23\n",
    "picks = mne.pick_types(raw_filtered.info, meg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Apply ICA and check for artifact's components \n",
    "ica = ICA(n_components=n_components, method=method, random_state=random_state)\n",
    "# print(ica)\n",
    "reject = dict(mag=5e-12, grad=4000e-13)\n",
    "ica.fit(raw_filtered, picks=picks, decim=decim, reject=reject)\n",
    "# print(ica)\n",
    "# ica.plot_components()\n",
    "# ica.plot_sources(raw_filtered, picks=range(0,ica.n_components_-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exclude components\n",
    "ica.exclude += [1,2,9,12] #edit indices\n",
    "ica.plot_overlay(raw_filtered, exclude=[1,2,9,12])\n",
    "# ica.save('/media/analogicalnexus/2568212B752CDB3B/MEG_Data/R505_ica_filtered.fif')\n",
    "ica.apply(raw_filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Epoching (Segmenting )\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter setup for syllable decoding\n",
    "# event_id_long = dict(nw1=173,nw3=175,w1=163,w3=165)\n",
    "event_id_long = dict(r=187,nr=188)\n",
    "# event_id_long = dict(s1=[173,163],s2=[174,164],s3=[175,165])\n",
    "tmin = -0.2\n",
    "tmax = 0.5\n",
    "baseline = (None,None)\n",
    "picks = mne.pick_types(raw_filtered.info, meg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(raw_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(raw_filtered, events, event_id_long, tmin, tmax, proj=False, picks=picks, baseline=baseline, decim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = mne.epochs.combine_event_ids(epochs,['w1','nw1'],{'s1':190})\n",
    "# epochs = mne.epochs.combine_event_ids(epochs,['w3','nw3'],{'s2':191})\n",
    "# epochs = mne.epochs.combine_event_ids(epochs,['nw3','w3'],{'s3':192})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs.event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Sensor space analysis\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rhyme.plot(spatial_colors=True, gfp=True, ylim=dict(mag=[-300,300]))\n",
    "# non_rhyme.plot(spatial_colors=True, gfp=True, ylim=dict(mag=[-300,300]))\n",
    "# rhyme.plot_topomap(times=[.0, .17, .4],vmin=-300,vmax=300)\n",
    "# non_rhyme.plot_topomap(times=[.0, .17, .4],vmin=-300,vmax=300)\n",
    "# evoked_dict = dict() \n",
    "# evoked_dict['rhyme'] = rhyme\n",
    "# evoked_dict['non_rhyme'] = non_rhyme\n",
    "# colors=dict(rhyme=\"Crimson\",non_rhyme=\"CornFlowerBlue\") \n",
    "# mne.viz.plot_compare_evokeds(evoked_dict, colors=colors,\n",
    "# picks=picks, gfp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# la=[0,1,2,3,39,41,42,43,44,52,58,67,71,80,82,83,84,85,108,130,131,132,133,134,135,136,151]\n",
    "# lp=[4,5,6,7,8,9,34,36,37,38,40,45,46,47,48,49,50,75,76,77,79,87,88,90,127,129,137]\n",
    "# ra=[20,22,23,24,26,59,60,61,62,63,65,89,92,95,99,100,114,115,116,117,118,145,147,148,152,155]\n",
    "# rp=[14,15,16,17,18,19,25,27,28,30,53,54,56,57,66,68,69,70,94,96,97,119,121,122,143,144]\n",
    "# lh=[0,1,2,3,39,41,42,43,44,52,58,67,71,80,82,83,84,85,108,130,131,132,133,134,135,136,151,4,5,6,7,8,9,34,36,37,38,40,45,46,47,48,49,50,75,76,77,79,87,88,90,127,129,137]\n",
    "# rh=[20,22,23,24,26,59,60,61,62,63,65,89,92,95,99,100,114,115,116,117,118,145,147,148,152,155, 14,15,16,17,18,19,25,27,28,30,53,54,56,57,66,68,69,70,94,96,97,119,121,122,143,144]\n",
    "# mne.viz.plot_compare_evokeds(evoked_dict, colors=colors,\n",
    "# picks=lh, gfp=True, ylim=dict(mag=[0,100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epochs.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Frequency domain analysis\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 500\n",
    "freqs = np.arange(8., 12., 1.)\n",
    "vmin, vmax = -.3e-25, .3e-25  # Define our color limits.\n",
    "n_cycles = freqs / 2.\n",
    "time_bandwidth = 8.0  # Same time-smoothing as (1), 7 tapers.\n",
    "\n",
    "#  signal.spectrogram(epochs.get_data(), sfreq)\n",
    "X = epochs.get_data()\n",
    "f,t,Sxx = (signal.spectrogram(X[0,0,:], fs=sfreq, nperseg=250, noverlap=240,nfft=500))\n",
    "# S = []\n",
    "S = np.zeros([X.shape[0], X.shape[1], Sxx.shape[0], Sxx.shape[1]], dtype = float)\n",
    "for e in range(X.shape[0]):\n",
    "    for c in range(X.shape[1]):\n",
    "        f,t,S[e,c,:,:] = (signal.spectrogram(X[e,c,:], fs=sfreq, nperseg=250, noverlap=240, nfft=500))\n",
    "#         S[e][c].append(Sxx)\n",
    "#         print(S)\n",
    "    \n",
    "\n",
    "# power = tfr_multitaper(epochs, freqs=freqs, n_cycles=n_cycles,\n",
    "#                          time_bandwidth=time_bandwidth, return_itc=False,average=False)\n",
    "# power = tfr_array_morlet(epochs.get_data(), sfreq=epochs.info['sfreq'],\n",
    "#                          freqs=freqs, n_cycles=n_cycles)\n",
    "\n",
    "# psds, freqs = psd_welch(raw, picks=picks, tmin=tmin, tmax=tmax,\n",
    "#                         fmin=fmin, fmax=fmax)\n",
    "\n",
    "# Baseline the output\n",
    "# rescale(power, epochs.times, (0., 0.1), mode='mean', copy=False)\n",
    "# Plot results. Baseline correct based on first 100 ms.\n",
    "# power.plot([0], baseline=(0., 0.1), mode='mean', vmin=vmin, vmax=vmax,\n",
    "#            title='Sim: Less time smoothing, more frequency smoothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - Decoding (MVPA)\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init scores\n",
    "trf_scores = np.zeros((S.shape[2], S.shape[3] ))\n",
    "\n",
    "# Loop through each frequency range of interest\n",
    "for i in range(S.shape[2]):\n",
    "\n",
    "    X = S[:,:,i,:]  # MEG signals: n_epochs, freq, n_times\n",
    "    y = epochs.events[:, 2]  # target: 1 or 3\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "    time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "\n",
    "    scores = cross_val_multiscore(time_decod, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "    # Mean scores across cross-validation splits\n",
    "    trf_scores[i,:] = np.mean(scores, axis=0)\n",
    "#     scores = np.mean(scores, axis=0)\n",
    "    \n",
    "#     # Plot\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(epochs.times, scores, label='score')\n",
    "#     ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "#     ax.set_xlabel('Times')\n",
    "#     ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "#     ax.legend()\n",
    "#     ax.axvline(.0, color='k', linestyle='-')\n",
    "#     ax.set_title('Sensor space decoding')\n",
    "#     plt.show()\n",
    "\n",
    "#     # You can retrieve the spatial filters and spatial patterns if you explicitly\n",
    "#     # use a LinearModel\n",
    "#     clf = make_pipeline(StandardScaler(), LinearModel(LogisticRegression()))\n",
    "#     time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "#     time_decod.fit(X, y)\n",
    "\n",
    "#     coef = get_coef(time_decod, 'patterns_', inverse_transform=True)\n",
    "#     evoked = mne.EvokedArray(coef, epochs.info, tmin=epochs.times[0])\n",
    "#     evoked.plot_joint(times=np.arange(0., .500, .100), title='patterns')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chance = np.mean(y)  # set chance level to white in the plot\n",
    "# trf_scores.plot([0], vmin=chance, title=\"Time-Frequency Decoding Scores\",\n",
    "#             cmap=plt.cm.Reds)\n",
    "\n",
    "\n",
    "plt.imshow(trf_scores[:,:], cmap='hot',interpolation='nearest', aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from mne.decoding import CSP\n",
    "\n",
    "n_components = 3\n",
    "svc = SVC(C=1, kernel='linear')\n",
    "csp = CSP(n_components=n_components, norm_trace=False)\n",
    "\n",
    "cv=ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "trf_scores = np.zeros((S.shape[2], S.shape[3] ))\n",
    "\n",
    "# Loop through each frequency range of interest\n",
    "for i in range(20):\n",
    "\n",
    "    scores = []\n",
    "    X = S[:,:,i,:]  # MEG signals: n_epochs, freq, n_times\n",
    "    labels = epochs.events[:, 2]  # target: 1 or 3\n",
    "    \n",
    "    for train_idx, test_idx in cv.split(labels):\n",
    "        y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "        X_train = csp.fit_transform(X[train_idx][:][:][:], y_train)\n",
    "        X_test = csp.transform(X[test_idx])\n",
    "\n",
    "        # fit classifier\n",
    "        svc.fit(X_train, y_train)\n",
    "\n",
    "        scores.append(svc.score(X_test, y_test))\n",
    "\n",
    "    # Printing the results\n",
    "#     print(scores)\n",
    "    class_balance = np.mean(labels == labels[0])\n",
    "    class_balance = max(class_balance, 1. - class_balance)\n",
    "    trf_scores[i,:] = (np.mean(scores))\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n",
    "        # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(scores, label='score')\n",
    "    ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "    ax.set_xlabel('Times')\n",
    "    ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "    ax.legend()\n",
    "    ax.axvline(.0, color='k', linestyle='-')\n",
    "    ax.set_title('Sensor space decoding')\n",
    "    plt.show()\n",
    "\n",
    "#     # You can retrieve the spatial filters and spatial patterns if you explicitly\n",
    "#     # use a LinearModel\n",
    "#     clf = make_pipeline(StandardScaler(), LinearModel(LogisticRegression()))\n",
    "#     time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "#     time_decod.fit(X, y)\n",
    "\n",
    "#     coef = get_coef(time_decod, 'patterns_', inverse_transform=True)\n",
    "#     evoked = mne.EvokedArray(coef, epochs.info, tmin=epochs.times[0])\n",
    "#     evoked.plot_joint(times=np.arange(0., .500, .100), title='patterns')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trf_scores[:,:], cmap='hot',interpolation='nearest', aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_scores[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
