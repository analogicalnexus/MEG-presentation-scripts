{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working Memory Decoding\n",
    "============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from mne import create_info, EpochsArray\n",
    "from mne.baseline import rescale\n",
    "from mne.time_frequency import (tfr_multitaper, tfr_stockwell, tfr_morlet,\n",
    "                                tfr_array_morlet)\n",
    "\n",
    "import warnings\n",
    "from mne.preprocessing import ICA\n",
    "warnings.filterwarnings('ignore')\n",
    "from mne import viz\n",
    "from mne.channels import Layout\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator,\n",
    "                          cross_val_multiscore, LinearModel, get_coef)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mne import Epochs, find_events, create_info\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "from mne.time_frequency import AverageTFR\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - IO\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /media/analogicalnexus/2568212B752CDB3B/MEG_Data/R507/R2507-ica-filtered-raw.fif...\n",
      "    Range : 0 ... 2779999 =      0.000 ...  2779.999 secs\n",
      "Ready.\n",
      "Opening raw data file /media/analogicalnexus/2568212B752CDB3B/MEG_Data/R507/R2507-ica-filtered-raw-1.fif...\n",
      "    Range : 2780000 ... 3009999 =   2780.000 ...  3009.999 secs\n",
      "Ready.\n",
      "Current compensation grade : 0\n",
      "Reading 0 ... 3009999  =      0.000 ...  3009.999 secs...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Raw  |  R2507-ica-filtered-raw.fif, n_channels x n_times : 193 x 3010000 (3010.0 sec), ~4.33 GB, data loaded>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading fif file\n",
    "# input_fname = '/media/analogicalnexus/2568212B752CDB3B/MEG_Data/R507/R2507_WMD-Filtered-raw.fif'\n",
    "filtered_out = '/media/analogicalnexus/2568212B752CDB3B/MEG_Data/R507/R2507-ica-filtered-raw.fif'\n",
    "# input_ica = '/media/analogicalnexus/2568212B752CDB3B/MEG_Data/R507/R2507-ica.fif'\n",
    "raw_filtered=mne.io.read_raw_fif(filtered_out)\n",
    "raw_filtered.load_data()\n",
    "# raw.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Filtering - Band Pass filter (1-160 Hz)\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Band pass filter\n",
    "# raw_filtered = raw.filter(l_freq=1, h_freq=160.0, fir_design='firwin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - ICA\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Reference - https://martinos.org/mne/dev/auto_tutorials/plot_ica_from_raw.html\n",
    "# #ICA parameters\n",
    "# n_components = 0.95  # if float, select n_components by explained variance of PCA\n",
    "# method = 'fastica'  # for comparison with EEGLAB try \"extended-infomax\" here\n",
    "# decim = 3  # we need sufficient statistics, not all time points -> saves time\n",
    "\n",
    "# # we will also set state of the random number generator - ICA is a\n",
    "# # non-deterministic algorithm, but we want to have the same decomposition\n",
    "# # and the same order of components each time this tutorial is run\n",
    "# random_state = 23\n",
    "# picks = mne.pick_types(raw_filtered.info, meg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Apply ICA and check for artifact's components \n",
    "# ica = ICA(n_components=n_components, method=method, random_state=random_state)\n",
    "# # print(ica)\n",
    "# reject = dict(mag=5e-12, grad=4000e-13)\n",
    "# ica.fit(raw_filtered, picks=picks, decim=decim, reject=reject)\n",
    "# # print(ica)\n",
    "# ica.plot_components()\n",
    "# ica.plot_sources(raw_filtered, picks=range(0,ica.n_components_-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Exclude components\n",
    "# bad_com = [0,1,2,3,4,5,6,11,24]\n",
    "# ica.exclude += bad_com #edit indices\n",
    "# ica.plot_overlay(raw_filtered, exclude=bad_com)\n",
    "# ica.save(input_ica)\n",
    "# ica.apply(raw_filtered)\n",
    "# raw.save(filtered_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Epoching (Segmenting )\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter setup for syllable decoding\n",
    "event_id_long = dict(nw1=173,nw3=175,w1=163,w3=165)\n",
    "# event_id_long = dict(r=187,nr=188)\n",
    "# event_id_long = dict(s1=[173,163],s2=[174,164],s3=[175,165])\n",
    "tmin = 10\n",
    "tmax = 12.5\n",
    "baseline = (None,None)\n",
    "picks = mne.pick_types(raw_filtered.info, meg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459 events found\n",
      "Events id: [163 164 165 173 174 175 178 187 188]\n"
     ]
    }
   ],
   "source": [
    "events = mne.find_events(raw_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 matching events found\n"
     ]
    }
   ],
   "source": [
    "epochs = mne.Epochs(raw_filtered, events, event_id_long, tmin, tmax, proj=False, picks=picks, baseline=baseline, decim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.epochs.combine_event_ids(epochs,['w1','nw1'],{'s1':190})\n",
    "epochs = mne.epochs.combine_event_ids(epochs,['w3','nw3'],{'s3':191})\n",
    "# epochs = mne.epochs.combine_event_ids(epochs,['nw3','w3'],{'s3':192})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs.event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Sensor space analysis\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rhyme.plot(spatial_colors=True, gfp=True, ylim=dict(mag=[-300,300]))\n",
    "# non_rhyme.plot(spatial_colors=True, gfp=True, ylim=dict(mag=[-300,300]))\n",
    "# rhyme.plot_topomap(times=[.0, .17, .4],vmin=-300,vmax=300)\n",
    "# non_rhyme.plot_topomap(times=[.0, .17, .4],vmin=-300,vmax=300)\n",
    "# evoked_dict = dict() \n",
    "# evoked_dict['rhyme'] = rhyme\n",
    "# evoked_dict['non_rhyme'] = non_rhyme\n",
    "# colors=dict(rhyme=\"Crimson\",non_rhyme=\"CornFlowerBlue\") \n",
    "# mne.viz.plot_compare_evokeds(evoked_dict, colors=colors,\n",
    "# picks=picks, gfp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# la=[0,1,2,3,39,41,42,43,44,52,58,67,71,80,82,83,84,85,108,130,131,132,133,134,135,136,151]\n",
    "# lp=[4,5,6,7,8,9,34,36,37,38,40,45,46,47,48,49,50,75,76,77,79,87,88,90,127,129,137]\n",
    "# ra=[20,22,23,24,26,59,60,61,62,63,65,89,92,95,99,100,114,115,116,117,118,145,147,148,152,155]\n",
    "# rp=[14,15,16,17,18,19,25,27,28,30,53,54,56,57,66,68,69,70,94,96,97,119,121,122,143,144]\n",
    "# lh=[0,1,2,3,39,41,42,43,44,52,58,67,71,80,82,83,84,85,108,130,131,132,133,134,135,136,151,4,5,6,7,8,9,34,36,37,38,40,45,46,47,48,49,50,75,76,77,79,87,88,90,127,129,137]\n",
    "# rh=[20,22,23,24,26,59,60,61,62,63,65,89,92,95,99,100,114,115,116,117,118,145,147,148,152,155, 14,15,16,17,18,19,25,27,28,30,53,54,56,57,66,68,69,70,94,96,97,119,121,122,143,144]\n",
    "# mne.viz.plot_compare_evokeds(evoked_dict, colors=colors,\n",
    "# picks=lh, gfp=True, ylim=dict(mag=[0,100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 102 events and 2501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "X = epochs.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 157, 1251)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Frequency domain analysis\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 102 events and 2501 original time points ...\n"
     ]
    }
   ],
   "source": [
    "sfreq = 500\n",
    "freqs = np.arange(8., 12., 1.)\n",
    "vmin, vmax = -.3e-25, .3e-25  # Define our color limits.\n",
    "n_cycles = freqs / 2.\n",
    "time_bandwidth = 8.0  # Same time-smoothing as (1), 7 tapers.\n",
    "\n",
    "#  signal.spectrogram(epochs.get_data(), sfreq)\n",
    "X = epochs.get_data()\n",
    "f,t,Sxx = (signal.spectrogram(X[0,0,:], fs=sfreq, nperseg=250, noverlap=249,nfft=500))\n",
    "# S = []\n",
    "S = np.zeros([X.shape[0], X.shape[1], Sxx.shape[0], Sxx.shape[1]], dtype = float)\n",
    "for e in range(X.shape[0]):\n",
    "    for c in range(X.shape[1]):\n",
    "        f,t,S[e,c,:,:] = (signal.spectrogram(X[e,c,:], fs=sfreq, nperseg=250, noverlap=249, nfft=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "(102, 157, 3, 1002)\n",
      "(102, 471, 1002)\n",
      "(102, 157, 4, 1002)\n",
      "(102, 628, 1002)\n",
      "(102, 157, 6, 1002)\n",
      "(102, 942, 1002)\n",
      "(102, 157, 9, 1002)\n",
      "(102, 1413, 1002)\n",
      "(102, 157, 21, 1002)\n",
      "(102, 3297, 1002)\n",
      "(102, 157, 71, 1002)\n",
      "(102, 11147, 1002)\n"
     ]
    }
   ],
   "source": [
    "freqs = np.array([[1,4],[3,7],[7,13],[13,22],[40,61],[70,141]])\n",
    "print(freqs.shape[0])\n",
    "for i in range(freqs.shape[0]):\n",
    "    R = S[:,:,freqs[i,0]:freqs[i,1],:]\n",
    "    print(R.shape)\n",
    "    Y = R.reshape(102, 157*(freqs[i,1]-freqs[i,0]), 1002)\n",
    "    print(Y.shape)\n",
    "# np.ravel(R[,:,:,]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - Decoding (MVPA)\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # init scores\n",
    "# trf_scores = np.zeros((S.shape[2], S.shape[3] ))\n",
    "\n",
    "# # Loop through each frequency range of interest\n",
    "# for i in range(S.shape[2]):\n",
    "\n",
    "#     X = S[:,:,i,:]  # MEG signals: n_epochs, freq, n_times\n",
    "#     y = epochs.events[:, 2]  # target: 1 or 3\n",
    "\n",
    "#     clf = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "#     time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "\n",
    "#     scores = cross_val_multiscore(time_decod, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "#     # Mean scores across cross-validation splits\n",
    "#     trf_scores[i,:] = np.mean(scores, axis=0)\n",
    "# #     scores = np.mean(scores, axis=0)\n",
    "    \n",
    "#     # Plot\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(epochs.times, scores, label='score')\n",
    "#     ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "#     ax.set_xlabel('Times')\n",
    "#     ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "#     ax.legend()\n",
    "#     ax.axvline(.0, color='k', linestyle='-')\n",
    "#     ax.set_title('Sensor space decoding')\n",
    "#     plt.show()\n",
    "\n",
    "#     # You can retrieve the spatial filters and spatial patterns if you explicitly\n",
    "#     # use a LinearModel\n",
    "#     clf = make_pipeline(StandardScaler(), LinearModel(LogisticRegression()))\n",
    "#     time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "#     time_decod.fit(X, y)\n",
    "\n",
    "#     coef = get_coef(time_decod, 'patterns_', inverse_transform=True)\n",
    "#     evoked = mne.EvokedArray(coef, epochs.info, tmin=epochs.times[0])\n",
    "#     evoked.plot_joint(times=np.arange(0., .500, .100), title='patterns')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chance = np.mean(y)  # set chance level to white in the plot\n",
    "# trf_scores.plot([0], vmin=chance, title=\"Time-Frequency Decoding Scores\",\n",
    "#             cmap=plt.cm.Reds)\n",
    "\n",
    "\n",
    "# plt.imshow(trf_scores[:,:], cmap='hot',interpolation='nearest', aspect='auto')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "trf_scores = np.zeros((S.shape[2], S.shape[3] ))\n",
    "\n",
    "freqs = np.array([[1,4],[3,7],[7,13],[13,22],[40,61],[70,141]])\n",
    "print(freqs.shape[0])\n",
    "for i in range(freqs.shape[0]):\n",
    "    R = S[:,:,freqs[i,0]:freqs[i,1],:]\n",
    "    X = R.reshape(102, 157*(freqs[i,1]-freqs[i,0]), 1002)\n",
    "    scores = []\n",
    "    y = epochs.events[:, 2]  # target: 1 or 3\n",
    "    clf = make_pipeline(StandardScaler(), LinearModel(LogisticRegression()))\n",
    "    time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "    time_decod.fit(X, y)\n",
    "    \n",
    "    scores = cross_val_multiscore(time_decod, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "\n",
    "    # Mean scores across cross-validation splits\n",
    "    trf_scores[i,:] = np.mean(scores, axis=0)\n",
    "    scores = np.mean(scores, axis=0)\n",
    "    \n",
    "        \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(range(0,1002,1), scores, label='score')\n",
    "    ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "    ax.set_xlabel('Times')\n",
    "    ax.set_ylabel('Accuracy')  # Area Under the Curve\n",
    "    ax.legend()\n",
    "    ax.axvline(.0, color='k', linestyle='-')\n",
    "    ax.set_title('Sensor space decoding')\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trf_scores[:,:], cmap='hot',interpolation='nearest', aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 157, 251, 1002)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_scores[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
